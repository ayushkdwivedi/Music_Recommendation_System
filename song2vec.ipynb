{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gensim.models.word2vec as w2v\n",
    "from gensim.corpora.textcorpus import TextCorpus\n",
    "import re\n",
    "from datetime import datetime\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529193595\n",
      "File size: 2529193595\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "def get_chunks(file_size):\n",
    "    chunk_start = 0\n",
    "    chunk_size = 0x20000\n",
    "    while chunk_start + chunk_size < file_size:\n",
    "        yield(chunk_start, chunk_size)\n",
    "        chunk_start += chunk_size\n",
    "    final_chunk_size = file_size - chunk_start\n",
    "    yield(chunk_start, final_chunk_size)\n",
    "\n",
    "def read_file_chunked(file_path):\n",
    "    with open(file_path,encoding='utf-8') as file_:\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        print(file_size)\n",
    "        print('File size: {}'.format(file_size))\n",
    "        progress = 0\n",
    "\n",
    "        for chunk_start, chunk_size in get_chunks(file_size):\n",
    "\n",
    "            file_chunk = file_.read(chunk_size)\n",
    "#             print((file_chunk))\n",
    "            f.write(file_chunk)\n",
    "            progress += len(file_chunk)\n",
    "            if(progress>=file_size/2):\n",
    "                break\n",
    "#             print('{0} of {1} bytes read'.format(progress, file_size))\n",
    "#             print('In Progress...')\n",
    "        print('Completed')\n",
    "\n",
    "f = open('prep.tsv', 'a+', encoding='utf-8')\n",
    "read_file_chunked('../Dataset/dataset.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('prep.tsv',encoding='utf-8')\n",
    "f1 = open('newprep.tsv','w',encoding='utf-8')\n",
    "for x in range(4781164):\n",
    "    s = f.readline()\n",
    "    l = s.split('\\t')\n",
    "    f1.write(l[0][5:]+'\\t'+l[1]+'\\t'+l[-1])\n",
    "f.close()\n",
    "f1.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp(time):\n",
    "    arr=re.split('-|T|Z|:',time)\n",
    "    date_time = arr[0]+arr[1]+arr[2]+arr[3]+arr[4]+arr[5]\n",
    "#     print(date_time)\n",
    "    return date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-05-04T23:08:57Z</td>\n",
       "      <td>Fuck Me Im Famous (Pacha Ibiza)-09-28-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-05-04T13:54:10Z</td>\n",
       "      <td>Composition 0919 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-05-04T13:52:04Z</td>\n",
       "      <td>Mc2 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-05-04T13:42:52Z</td>\n",
       "      <td>Hibari (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-05-04T13:42:11Z</td>\n",
       "      <td>Mc1 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID             TimeStamp                                        Song\n",
       "0       1  2009-05-04T23:08:57Z  Fuck Me Im Famous (Pacha Ibiza)-09-28-2007\n",
       "1       1  2009-05-04T13:54:10Z           Composition 0919 (Live_2009_4_15)\n",
       "2       1  2009-05-04T13:52:04Z                        Mc2 (Live_2009_4_15)\n",
       "3       1  2009-05-04T13:42:52Z                     Hibari (Live_2009_4_15)\n",
       "4       1  2009-05-04T13:42:11Z                        Mc1 (Live_2009_4_15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['UserID', 'TimeStamp', 'Song'] \n",
    "data = pd.read_csv('newprep.tsv',delimiter='\\t',encoding='utf-8', names=columns,header=None)\n",
    "data.head()\n",
    "print(len(data))\n",
    "\n",
    "\n",
    "data.sort_values(by=['UserID','TimeStamp'],ascending=[True,True],inplace=True)\n",
    "MPS = {}\n",
    "idnum = data.iloc[0]['UserID']\n",
    "song = data.iloc[0]['Song']\n",
    "ts = data.iloc[0]['TimeStamp']\n",
    "l = [song]\n",
    "for i in range(1,len(data)):\n",
    "    print(i)\n",
    "    newid = data.iloc[i]['UserID']\n",
    "    tsnew = data.iloc[i]['TimeStamp']\n",
    "#     print(tsnew)\n",
    "    newsong = data.iloc[i]['Song']\n",
    "    if newid == idnum:\n",
    "        ts1 = timestamp(data.iloc[i]['TimeStamp'])\n",
    "        ts2 = timestamp(data.iloc[i-1]['TimeStamp'])\n",
    "        d = pd.Timedelta(datetime.strptime(ts1, '%Y%m%d%H%M%S') - datetime.strptime(ts2, '%Y%m%d%H%M%S')).seconds\n",
    "        if d < 800:\n",
    "            l.append(data.iloc[i]['Song'])\n",
    "        else:\n",
    "            if idnum in MPS.keys():\n",
    "                MPS[idnum].append(l)\n",
    "            else:\n",
    "                MPS[idnum] = [l]\n",
    "            l = []\n",
    "            l.append(data.iloc[i]['Song'])\n",
    "    else:\n",
    "        if idnum in MPS.keys():\n",
    "            MPS[idnum].append(l)\n",
    "        else:\n",
    "            MPS[idnum] = [l]\n",
    "        idnum = newid\n",
    "        l = []\n",
    "        l.append(data.iloc[i]['Song'])\n",
    "if l not in MPS[idnum]:\n",
    "    if idnum in MPS.keys():\n",
    "        MPS[idnum].append(l)\n",
    "    else:\n",
    "        MPS[idnum] = [l]\n",
    "for user in MPS:\n",
    "    for ele in MPS[user]:\n",
    "        if len(ele) < 10:\n",
    "            MPS[user].remove(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"MPS.txt\",\"w\",encoding='utf-8')\n",
    "f.write(str(MPS))\n",
    "f.close()\n",
    "\n",
    "pickle_out = open(\"dict.pickle\",\"wb\")\n",
    "pickle.dump(MPS, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125181\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "# f = open('MPS1.txt','r',encoding='utf-8')\n",
    "for i in range(len(MPS)):\n",
    "    l = MPS[i+1]\n",
    "#     print(len(l))\n",
    "    for j in range(len(l)):\n",
    "        if len(l[j]) > 10:\n",
    "            corpus.append(l[j])\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2vec = w2v.Word2Vec(sg=1,seed=1,size=100,min_count=10,window=5)\n",
    "song2vec.build_vocab(corpus)\n",
    "# # Preprocess the songs that contain unprintable unicode characters\n",
    "# vocabulary1=list(song2vec.wv.vocab)\n",
    "# print(len(vocabulary1))\n",
    "# vocabulary1=list(song2vec.wv.vocab)\n",
    "# vocabulary1=[x.encode('UTF8') for x in vocabulary1]\n",
    "# vocabulary=[]\n",
    "# for word in vocabulary1:\n",
    "#     if re.match('[A-Za-z0-9\\'\\?\\&\\)\\(\\+\\!\\-\\*\\.\\, ]+$',word):\n",
    "#         vocabulary.append(word)\n",
    "\n",
    "# vocabulary.sort()\n",
    "# print(vocabulary)\n",
    "# print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'song2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-372571acf6eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msong2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"song2vec.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'song2vec' is not defined"
     ]
    }
   ],
   "source": [
    "song2vec.save(\"song2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31229520, 39464000)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song2vec.train(corpus,total_examples=len(corpus),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(song2vec.most_similar(u'The Boy Looked At Johnny',topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print song2vec.most_similar('Gang Of Gin',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('MPS.txt','r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='MPS.txt' mode='r' encoding='utf-8'>\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "with open('MPS.txt','r',encoding='utf-8') as f:\n",
    "for line in f:\n",
    "    (key, val) = line.split()\n",
    "    d[int(key)] = val\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
